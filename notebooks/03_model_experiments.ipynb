{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "961b0371-acdd-45cd-a1d9-2d718fc66e7d",
   "metadata": {},
   "source": [
    "# 03 - Model Experiments: Churn Prediction\n",
    "\n",
    "## Goals:\n",
    "- Try different classifiers (Random Forest, XGBoost, etc.)\n",
    "- Add/remove features and observe impact\n",
    "- Track everything with MLflow\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸš€ MLflow Server Command Explained\n",
    "\n",
    "```bash\n",
    "\n",
    "mlflow server \\\n",
    "  --backend-store-uri sqlite:///backend.db \\\n",
    "  --default-artifact-root ./mlruns \\\n",
    "  --host 127.0.0.1 \\\n",
    "  --port 5000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65781fbf-9ac9-4330-a0f7-e637005d34d9",
   "metadata": {},
   "source": [
    "## 1. Load the Processed Data\n",
    "\n",
    "We load the train and test datasets that were previously cleaned and saved to the `data/processed/` folder.\n",
    "\n",
    "These files will be used as the base input for our feature engineering and model training experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01d34829-33d1-4434-9ca4-5adaf8214968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Train shape: (7088, 19)\n",
      "âœ… Test shape: (3039, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer_Age</th>\n",
       "      <th>Dependent_count</th>\n",
       "      <th>Months_on_book</th>\n",
       "      <th>Total_Relationship_Count</th>\n",
       "      <th>Months_Inactive_12_mon</th>\n",
       "      <th>Contacts_Count_12_mon</th>\n",
       "      <th>Credit_Limit</th>\n",
       "      <th>Total_Revolving_Bal</th>\n",
       "      <th>Total_Trans_Amt</th>\n",
       "      <th>Total_Trans_Ct</th>\n",
       "      <th>Total_Amt_Chng_Q4_Q1</th>\n",
       "      <th>Total_Ct_Chng_Q4_Q1</th>\n",
       "      <th>Avg_Utilization_Ratio</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Education_Level</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Income_Category</th>\n",
       "      <th>Card_Category</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44</td>\n",
       "      <td>3</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6680.0</td>\n",
       "      <td>1839</td>\n",
       "      <td>7632</td>\n",
       "      <td>95</td>\n",
       "      <td>0.617</td>\n",
       "      <td>0.532</td>\n",
       "      <td>0.275</td>\n",
       "      <td>F</td>\n",
       "      <td>Uneducated</td>\n",
       "      <td>Married</td>\n",
       "      <td>Less than $40K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2884.0</td>\n",
       "      <td>2517</td>\n",
       "      <td>4809</td>\n",
       "      <td>87</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.873</td>\n",
       "      <td>F</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Single</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Blue</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>14858.0</td>\n",
       "      <td>1594</td>\n",
       "      <td>4286</td>\n",
       "      <td>72</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.107</td>\n",
       "      <td>M</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Married</td>\n",
       "      <td>$80K - $120K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2638.0</td>\n",
       "      <td>2092</td>\n",
       "      <td>1868</td>\n",
       "      <td>43</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.793</td>\n",
       "      <td>M</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Married</td>\n",
       "      <td>$40K - $60K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47</td>\n",
       "      <td>5</td>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8896.0</td>\n",
       "      <td>1338</td>\n",
       "      <td>4252</td>\n",
       "      <td>70</td>\n",
       "      <td>0.741</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.150</td>\n",
       "      <td>M</td>\n",
       "      <td>Doctorate</td>\n",
       "      <td>Single</td>\n",
       "      <td>Less than $40K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Customer_Age  Dependent_count  Months_on_book  Total_Relationship_Count  \\\n",
       "0            44                3              36                         2   \n",
       "1            39                1              34                         3   \n",
       "2            52                1              36                         4   \n",
       "3            34                0              17                         4   \n",
       "4            47                5              36                         3   \n",
       "\n",
       "   Months_Inactive_12_mon  Contacts_Count_12_mon  Credit_Limit  \\\n",
       "0                       3                      3        6680.0   \n",
       "1                       1                      1        2884.0   \n",
       "2                       2                      2       14858.0   \n",
       "3                       1                      4        2638.0   \n",
       "4                       1                      2        8896.0   \n",
       "\n",
       "   Total_Revolving_Bal  Total_Trans_Amt  Total_Trans_Ct  Total_Amt_Chng_Q4_Q1  \\\n",
       "0                 1839             7632              95                 0.617   \n",
       "1                 2517             4809              87                 0.693   \n",
       "2                 1594             4286              72                 0.510   \n",
       "3                 2092             1868              43                 0.591   \n",
       "4                 1338             4252              70                 0.741   \n",
       "\n",
       "   Total_Ct_Chng_Q4_Q1  Avg_Utilization_Ratio Gender Education_Level  \\\n",
       "0                0.532                  0.275      F      Uneducated   \n",
       "1                0.740                  0.873      F        Graduate   \n",
       "2                0.636                  0.107      M         Unknown   \n",
       "3                0.344                  0.793      M        Graduate   \n",
       "4                0.591                  0.150      M       Doctorate   \n",
       "\n",
       "  Marital_Status Income_Category Card_Category  churn  \n",
       "0        Married  Less than $40K          Blue      0  \n",
       "1         Single         Unknown          Blue      0  \n",
       "2        Married    $80K - $120K          Blue      0  \n",
       "3        Married     $40K - $60K          Blue      0  \n",
       "4         Single  Less than $40K          Blue      0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Load train and test data\n",
    "\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Load processed train and test sets\n",
    "train_df = pd.read_csv(\"../data/processed/train.csv\")\n",
    "test_df = pd.read_csv(\"../data/processed/test.csv\")\n",
    "\n",
    "print(f\"âœ… Train shape: {train_df.shape}\")\n",
    "print(f\"âœ… Test shape: {test_df.shape}\")\n",
    "\n",
    "# Optional: show a few rows\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e4b5aec-44e7-4362-9eb8-eae1c0fe0bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X_train = train_df.drop(columns=[\"churn\"])  # Drop unused target + unused col\n",
    "y_train = train_df[\"churn\"]\n",
    "\n",
    "X_test = test_df.drop(columns=[\"churn\"])\n",
    "y_test = test_df[\"churn\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269865e2-baf3-4346-a822-79467f444cad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72e19e9b-0216-47ae-937e-1e919c6f5e68",
   "metadata": {},
   "source": [
    "## 2. Select Features and Target\n",
    "\n",
    "We define the list of features to use for model training and isolate the target variable (`churn`). \n",
    "\n",
    "These features include both numerical and categorical columns, so we'll handle preprocessing later using a pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d8a200a-2900-4f48-86aa-95be82008f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 1. Define your custom feature engineering logic ===\n",
    "def add_interaction_features(df):\n",
    "    df = df.copy()\n",
    "    df[\"Avg_Transaction_Amt\"] = df[\"Total_Trans_Amt\"] / (df[\"Total_Trans_Ct\"] + 1e-3)\n",
    "    df[\"Revolve_to_Limit\"] = df[\"Total_Revolving_Bal\"] / (df[\"Credit_Limit\"] + 1e-3)\n",
    "    df[\"AmtCt_Chg_Ratio\"] = df[\"Total_Amt_Chng_Q4_Q1\"] / (df[\"Total_Ct_Chng_Q4_Q1\"] + 1e-3)\n",
    "    return df\n",
    "\n",
    "# Wrap it as a FunctionTransformer\n",
    "interaction_transformer = FunctionTransformer(add_interaction_features)\n",
    "\n",
    "# === 2. Separate features ===\n",
    "categorical = [\n",
    "    \"Gender\", \"Education_Level\", \"Marital_Status\", \n",
    "    \"Income_Category\", \"Card_Category\"\n",
    "]\n",
    "\n",
    "numerical_to_scale = [\n",
    "    \"Credit_Limit\", \"Total_Revolving_Bal\", \n",
    "    \"Total_Trans_Amt\", \"Total_Trans_Ct\", \n",
    "    \"Avg_Utilization_Ratio\", \"Avg_Transaction_Amt\", \n",
    "    \"Revolve_to_Limit\", \"AmtCt_Chg_Ratio\"\n",
    "]\n",
    "\n",
    "numerical_no_scale = [\n",
    "    \"Customer_Age\", \"Dependent_count\", \"Months_on_book\",\n",
    "    \"Total_Relationship_Count\", \"Months_Inactive_12_mon\",\n",
    "    \"Contacts_Count_12_mon\", \"Total_Amt_Chng_Q4_Q1\", \n",
    "    \"Total_Ct_Chng_Q4_Q1\"\n",
    "]\n",
    "\n",
    "# === 3. Define transformers ===\n",
    "\n",
    "cat_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "num_scale_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "num_noscale_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\"))\n",
    "])\n",
    "\n",
    "# === 4. Compose all into one ColumnTransformer ===\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num_scaled\", num_scale_transformer, numerical_to_scale),\n",
    "    (\"num_noscale\", num_noscale_transformer, numerical_no_scale),\n",
    "    (\"cat\", cat_transformer, categorical)\n",
    "])\n",
    "\n",
    "# === 5. Final pipeline with feature engineering + preprocessor ===\n",
    "full_pipeline = Pipeline([\n",
    "    (\"feature_engineering\", interaction_transformer),\n",
    "    (\"preprocessor\", preprocessor)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d1a2d9-3576-4fb0-ab12-bb75f8508a66",
   "metadata": {},
   "source": [
    "## 3. Train + evaluate baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c15c25d9-6710-40b1-bb7f-1c435b711aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Accuracy: 0.9519578808818691\n",
      "âœ… ROC AUC: 0.9843969899300179\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Combine preprocessing pipeline with the classifier\n",
    "rf_pipeline = Pipeline([\n",
    "    (\"feature_pipeline\", full_pipeline),\n",
    "    (\"classifier\", RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42))\n",
    "])\n",
    "\n",
    "# Fit the model\n",
    "rf_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = rf_pipeline.predict(X_test)\n",
    "y_proba = rf_pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate\n",
    "print(\"âœ… Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"âœ… ROC AUC:\", roc_auc_score(y_test, y_proba))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1feddeba-dcd5-4dbc-a44d-8595aa53ba4b",
   "metadata": {},
   "source": [
    "## 4. MLflow tracking block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a33019ef-63dc-4453-a3c0-071c572bc0be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/10 10:10:52 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/07/10 10:10:59 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Accuracy: 0.9520\n",
      "âœ… ROC AUC: 0.9844\n",
      "ðŸƒ View run capricious-kit-713 at: http://127.0.0.1:5000/#/experiments/1/runs/9b94b41f1f394f9dbb45fcf2e2ddf6f7\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Set the experiment name (create it if not exists)\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "mlflow.set_experiment(\"churn-pipeline-baseline-models\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    # Log model name as a tag\n",
    "    mlflow.set_tag(\"model\", \"random_forest\")\n",
    "\n",
    "    # Define model params\n",
    "    rf_params = {\n",
    "        \"n_estimators\": 100,\n",
    "        \"max_depth\": 10,\n",
    "        \"random_state\": 42\n",
    "    }\n",
    "    mlflow.log_params(rf_params)\n",
    "\n",
    "    # Create pipeline\n",
    "    rf_pipeline = Pipeline([\n",
    "        (\"feature_pipeline\", full_pipeline),\n",
    "        (\"classifier\", RandomForestClassifier(**rf_params))\n",
    "    ])\n",
    "\n",
    "    # Fit\n",
    "    rf_pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Predict\n",
    "    y_pred = rf_pipeline.predict(X_test)\n",
    "    y_proba = rf_pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Metrics\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "    mlflow.log_metric(\"accuracy\", acc)\n",
    "    mlflow.log_metric(\"roc_auc\", roc_auc)\n",
    "\n",
    "    # Log full pipeline\n",
    "    mlflow.sklearn.log_model(rf_pipeline, artifact_path=\"model\")\n",
    "\n",
    "    print(f\"âœ… Accuracy: {acc:.4f}\")\n",
    "    print(f\"âœ… ROC AUC: {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d279b67-d024-4c52-bd81-34479e5e3e7b",
   "metadata": {},
   "source": [
    "## 4.a (Optional) Register best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8b6fc04-5521-4be4-916e-b24ad94411f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_log_model(model, model_name, extra_params=None):\n",
    "    mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "    mlflow.set_experiment(\"churn-pipeline-baseline-models\")\n",
    "    \n",
    "    with mlflow.start_run():\n",
    "        mlflow.set_tag(\"model\", model_name)\n",
    "        \n",
    "        # Automatically extract model parameters\n",
    "        model_params = model.get_params()\n",
    "        \n",
    "        # Merge with any manually passed params (optional)\n",
    "        if extra_params:\n",
    "            model_params.update(extra_params)\n",
    "        \n",
    "        mlflow.log_params(model_params)\n",
    "\n",
    "        pipeline = Pipeline([\n",
    "            (\"feature_pipeline\", full_pipeline),\n",
    "            (\"classifier\", model)\n",
    "        ])\n",
    "\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        y_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        roc_auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "        mlflow.log_metric(\"accuracy\", acc)\n",
    "        mlflow.log_metric(\"roc_auc\", roc_auc)\n",
    "\n",
    "        mlflow.sklearn.log_model(pipeline, artifact_path=\"model\")\n",
    "\n",
    "        print(f\"âœ… {model_name} - Accuracy: {acc:.4f}, ROC AUC: {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85de5159-9ad0-4b48-8202-1bbafe1bb8ef",
   "metadata": {},
   "source": [
    "## ðŸ§ª Step 5: Model Experimentation\n",
    "\n",
    "Now that we have a complete preprocessing and feature engineering pipeline, we can experiment with different models to evaluate their performance.\n",
    "\n",
    "Instead of repeating boilerplate code for each model, we define a **utility function** `train_and_log_model()` that:\n",
    "\n",
    "- Creates a pipeline with preprocessing + model\n",
    "- Fits the model on the training set\n",
    "- Logs model parameters and metrics (Accuracy, ROC AUC) to MLflow\n",
    "- (Optional) Skips saving the model to S3 while weâ€™re in the experimentation phase\n",
    "\n",
    "This way, we can try out multiple models easily and compare their performance directly in the MLflow UI (`http://127.0.0.1:5000`).\n",
    "\n",
    "Typical models to test include:\n",
    "- âœ… Random Forest\n",
    "- âœ… Logistic Regression\n",
    "- âœ… Gradient Boosting\n",
    "- âœ… XGBoost\n",
    "\n",
    "Once we identify the best-performing model, we can:\n",
    "- Save it using `mlflow.sklearn.log_model()`\n",
    "- Register it in the **Model Registry**\n",
    "- Deploy or version it as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23192ad0-d134-4cd0-943c-9538c29d2257",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/10 10:13:34 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/07/10 10:13:36 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… random_forest - Accuracy: 0.9520, ROC AUC: 0.9844\n",
      "ðŸƒ View run chill-bass-176 at: http://127.0.0.1:5000/#/experiments/1/runs/01b82c662ffd464aa19ebeaeb502f4fe\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/10 10:13:36 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/07/10 10:13:38 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… logistic_regression - Accuracy: 0.9075, ROC AUC: 0.9280\n",
      "ðŸƒ View run masked-lynx-887 at: http://127.0.0.1:5000/#/experiments/1/runs/542941524bef48e89b44af1c87eb02e6\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/10 10:13:40 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/07/10 10:13:42 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… gradient_boosting - Accuracy: 0.9599, ROC AUC: 0.9879\n",
      "ðŸƒ View run worried-horse-40 at: http://127.0.0.1:5000/#/experiments/1/runs/6dad04fb62244dbea427485d505eccf3\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/churn-clv-mlops/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:13:43] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "2025/07/10 10:13:43 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/07/10 10:13:45 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… xgboost - Accuracy: 0.9707, ROC AUC: 0.9920\n",
      "ðŸƒ View run wise-shrew-85 at: http://127.0.0.1:5000/#/experiments/1/runs/e2a291c40dd940dc8b3e703be56ba1a7\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/1\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "train_and_log_model(\n",
    "    RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42),\n",
    "    model_name=\"random_forest\",\n",
    "    extra_params={\"n_estimators\": 100, \"max_depth\": 10}\n",
    ")\n",
    "\n",
    "# Logistic Regression\n",
    "train_and_log_model(\n",
    "    LogisticRegression(max_iter=500),\n",
    "    model_name=\"logistic_regression\",\n",
    "    extra_params={\"max_iter\": 500}\n",
    ")\n",
    "\n",
    "# Gradient Boosting\n",
    "train_and_log_model(\n",
    "    GradientBoostingClassifier(n_estimators=100, learning_rate=0.1),\n",
    "    model_name=\"gradient_boosting\",\n",
    "    extra_params={\"n_estimators\": 100, \"learning_rate\": 0.1}\n",
    ")\n",
    "\n",
    "# XGBoost\n",
    "train_and_log_model(\n",
    "    XGBClassifier(n_estimators=100, use_label_encoder=False, eval_metric='logloss'),\n",
    "    model_name=\"xgboost\",\n",
    "    extra_params={\"n_estimators\": 100}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c760cb-c8e8-460b-958e-3e623d145e34",
   "metadata": {},
   "source": [
    "## 7. Model Selection: Comparing Baselines\n",
    "Now that weâ€™ve trained and logged four models using a shared preprocessing pipeline, we evaluate their performance using ROC AUC and accuracy. \n",
    "Based on this comparison, weâ€™ll choose one or two models for further tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4482ae5d-90b8-43b5-8989-4b69674a7a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "train_and_log_model() got an unexpected keyword argument 'params'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 39\u001b[0m\n\u001b[1;32m     36\u001b[0m best_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_name\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxgboost_tuned\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# 5. Call your existing function ðŸŽ‰\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m \u001b[43mtrain_and_log_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbest_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnamed_steps\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclassifier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Only pass the classifier\u001b[39;49;00m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mxgboost_tuned\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbest_params\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: train_and_log_model() got an unexpected keyword argument 'params'"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"xgboost\")\n",
    "\n",
    "\n",
    "\n",
    "# 1. Define the pipeline with XGBoost\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\", random_state=42)\n",
    "pipeline = Pipeline([\n",
    "    (\"feature_pipeline\", full_pipeline),\n",
    "    (\"classifier\", xgb)\n",
    "])\n",
    "\n",
    "# 2. Define parameter grid\n",
    "param_grid = {\n",
    "    \"classifier__n_estimators\": [100, 150],\n",
    "    \"classifier__max_depth\": [3, 5, 7],\n",
    "    \"classifier__learning_rate\": [0.05, 0.1]\n",
    "}\n",
    "\n",
    "# 3. Fit grid search\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    cv=3,\n",
    "    scoring=\"roc_auc\",\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 4. Extract the best model and params\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Optional: add back model_name to params dict\n",
    "best_params[\"model_name\"] = \"xgboost_tuned\"\n",
    "\n",
    "# 5. Call your existing function ðŸŽ‰\n",
    "train_and_log_model(\n",
    "    model=best_model.named_steps[\"classifier\"],  # Only pass the classifier\n",
    "    model_name=\"xgboost_tuned\",\n",
    "    params=best_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ea20899-7814-4cf7-8e39-e36fccd28b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "model_uri = \"s3://mlops-churn-analytics-falcon/mlflow-artifacts/2/models/m-7cb7b517788c48a5ac1aa5808135197f/artifacts/\"\n",
    "model = mlflow.sklearn.load_model(model_uri)\n",
    "\n",
    "# Use it for predictions\n",
    "preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c6c0ddf-934b-4988-8ccd-013461678bb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e246e1-2444-42bf-a2af-b2f52816e45e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (churn-clv-mlops)",
   "language": "python",
   "name": "churn-clv-mlops"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
